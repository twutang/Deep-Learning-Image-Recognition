{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_CW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "scylC1qNuBY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Baseline Code\n",
        "\n",
        "This code introduces a two-step training for the N-HPatches problem. In N-HPatches problem, we aim to generate a patch descriptor that is able to perform successfully tasks such as matching, retrieval or verification. \n",
        "\n",
        "Contrary to classical HPatches dataset, in N-HPatches, images contain random non-smooth perturbations produced by a synthetic noise. This noise could be critical when training the descriptor, therefore, we introduce a denoising model that could help us to deal with those perturbations. Denoising models have been already introduced in the course [tutorials](https://github.com/MatchLab-Imperial/deep-learning-course) and lectures, their objective is to generate a clean/denoised version of the input image.  We will refer in this code to the images with noise as `noisy`, to the images after applying the denoise model as `denoised` and the original patches from HPatches (so no extra noise added) which are used as ground-truth for the denoising step as `clean`. \n",
        "\n",
        "\n",
        "Thus, we aim to minimize the noise in images before the second step, which is computing a feature vector, also called descriptor. Those descriptions must be a powerful representation of the input patches. The idea behind is that if two descriptors belong two similar patches, they should be close to each other, i.e. have a low Euclidean distance. See figure below:\n",
        "\n",
        "![](https://i.ibb.co/4tvm3Vh/descriptorspace.png)\n",
        "\n",
        "This baseline code gives a method you can use to compare to whatever another approach you develop.  There are several other approaches you can test to see if there is any improvement, e.g. train the descriptor directly with noisy patches, without the denoising model. However, this code provides some guidance about how to implement the different blocks, how to stack them if desired, how to read the data and how to evaluate the method.\n",
        "\n",
        "The values given can be improved without changing the core method, only by tuning correctly the hyperparameters or giving it more training time, among others.\n",
        "\n",
        "As a first step of the project, you should get familiar with the problem and the provided code, so you can develop more complex and robust algorithms afterward. "
      ]
    },
    {
      "metadata": {
        "id": "iamuRgeiNLjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Safety Check\n",
        "\n",
        "As Google Colab is an external platform, we cannot guarantee that everytime you connect to a remote server, you will have the same amount of RAM or video RAM. For that reason, we will first check the amount of memory we have in the notebook. RAM should be around 12.9 GB, which is enough to load the datasets in memory. Also, usually, we have available 11.4 GB of GPU memory, which is more than enough to run this code. However, some users reported having only 500 MB of GPU memory. If you have that amount, restart the environment to see if you get the corresponding 11.4 GB."
      ]
    },
    {
      "metadata": {
        "id": "ZZG4BqkENEyd",
        "colab_type": "code",
        "outputId": "aae1b083-1370-4c5c-afe7-5a5f04034afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python2.7/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBvIvBoyg68g",
        "colab_type": "code",
        "outputId": "2d28d163-22a3-444a-ad11-4912db6131ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('RAM Free: 12.9 GB', ' | Proc size: 152.0 MB')\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMiynJ7p-zI8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Functions and Data\n",
        "\n",
        "The first step is to clone the GitHub repository of the course, which contains already implemented functions. You can use your own function and import them here doing the same. In addition, we are going to download and extract the N-HPatches data. \n",
        "\n",
        "As a note, in colab, we can run terminal commands by using ```!```. Also, by using ```%``` we have access to the [built-in IPython magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-cd), which we will use to move through directories (`cd` command). It takes around 5 minutes to download and unzip the dataset. \n"
      ]
    },
    {
      "metadata": {
        "id": "yV1m-9ZGuKGj",
        "colab_type": "code",
        "outputId": "9d7992ea-ebce-4e6c-86e4-589616548b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras_triplet_descriptor'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)   \u001b[K\rremote: Counting objects:  66% (2/3)   \u001b[K\rremote: Counting objects: 100% (3/3)   \u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 181 (delta 0), reused 1 (delta 0), pack-reused 178\u001b[K\n",
            "Receiving objects: 100% (181/181), 149.87 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n",
            "Checking out files: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pyZSqhZ5LACT",
        "colab_type": "code",
        "outputId": "0521f5e3-eb72-477e-eb48-a62cb511fc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "307CBCL-FjX4",
        "colab_type": "code",
        "outputId": "e2ec3d41-7f82-4cbc-fe62-99d1fe278c59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-21 10:02:11--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 185.235.236.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|185.235.236.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-21 10:02:12--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-03-21 10:02:12--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 185.235.236.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|185.235.236.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!MGBAWgiw1tfG3mAy_puqkH_PnpAjlJj0_JOPWAfrz6aNoRhCz4qKzNNScIQqNvvGy11JlEbzFALKUGPYQerk_Kq0uK-POhz0-b_we6_caHxRUqbodGZGOZ2olalp2vzR9UwZRGhtQoEGcHhASk-1ytC3gkWUrAega4D98DW9RSeG70uXyvAdPkgGLgPj_FvBGsfQL0pvCb0h-gilH4YYlfa7H8awiRJCPGsKg81q041sPe9o_rzmxEOSTpuBQXWvpat5lfQVlGNwT5-BZCS3aAWDkauuRW4CN66iiZ2Z7BOHM8DF6nW1SsepZj0xxAWeVm0UoT-qsjutZuj0BYlk7AJXBAZbdb7kO1Pj0wMdA0dafskFfFX2tXZhyPTP68s8qftLCb9G7tpOVSkqpurReJiV8fzkISZUTsaSlAATatnVDcidQPdGqoXdunnFCbIP-LUzMJwTQTrrJazLZv_EeTmJPmw8KgNmkpPrrF-Qp1MV6FRxCUWT5ibqX_1c-ydizTxnzCKgSgUwF73sZbbqURxbjA0yUitzeg39a1Df0Q87eaC2kRwFu81XYaV7fYBBgoycix_qcID2YbN8YC0aXE282MxcisS_LqGVI5t3rrh395XVpI7MgI37u2M_LSFQKHmqnvyKwODf2qlXFPJTjNCzQwvoyA0P5Td8HAm3HU5kv677raBCHzrB4yo1G-CWk5GN5JYArHllWoRsIJ_sXrkv9IhBJ5f9rrE_WAusEQuSBY2zenHC4xpunUwjUgi8QbPIEFfr1uPin2SAKOvw_6g91uOCoAPw4wDpPe28ZIEaaadRB8PlwOZ1N0_2xMpStT_P2nmFKq937aA7r7scFTGoXCPSRaYLjQ29wDO0Z1PT_2PXSGuAeYMMNkFbrZdzxgWwpSXU9PwnE7YClr3nxbOcH9OS6XVQwQYlE0dCFN5T4i4fsSnhUBIfikkjP0Kpy4Uhx48eFT9ak-J03qf0roaqvrpvWtkA5tPDvP4M10pCYo8_P947lkgM_hyabL4H_af43mXaIUIQAUw2-C7vV_fUAah1bUeopAc9LSGNv8jfIUFruRx12LhubBe-1-Y5Nl8gMkkrwyZsWbL6gyW54GroGsOR_J2RWtPcmirsBNwnWIEBhle67_YqiENbGNwy0Q4PXlZkDKiXqDokSFL1iUjKmSjilYPoz81wxV-6iV_sVP4ZpIkl0QFuWCLwg7Lhp79-p6hLOrwHPO8NML4ZuVjghVtsXXOIF9BGCHYUI0Uc_IMgGNkELPat2s2pwEjGpk3ZgRRu3gWVtAtbVDZi5qr68dp4oiSzcRAIrgorr_hTY5TIeFXRy8oxSKTaDY20-dyhKia4aGhGKtGFNz_bCJOdhvZGPtUnfck69dMn6LaI9JRzkKYDPJT512cC-mDs8-OQoYmrL9P8UJlpxdspD0CCwV2bsQgqzMYwEgRn5a3Y9tlkVOU0RHEluQI-eJgs9YSgrmh8nhRYNVIJGm0e9jj9Jbs2s6sDI_M./download [following]\n",
            "--2019-03-21 10:02:12--  https://public.boxcloud.com/d/1/b1!MGBAWgiw1tfG3mAy_puqkH_PnpAjlJj0_JOPWAfrz6aNoRhCz4qKzNNScIQqNvvGy11JlEbzFALKUGPYQerk_Kq0uK-POhz0-b_we6_caHxRUqbodGZGOZ2olalp2vzR9UwZRGhtQoEGcHhASk-1ytC3gkWUrAega4D98DW9RSeG70uXyvAdPkgGLgPj_FvBGsfQL0pvCb0h-gilH4YYlfa7H8awiRJCPGsKg81q041sPe9o_rzmxEOSTpuBQXWvpat5lfQVlGNwT5-BZCS3aAWDkauuRW4CN66iiZ2Z7BOHM8DF6nW1SsepZj0xxAWeVm0UoT-qsjutZuj0BYlk7AJXBAZbdb7kO1Pj0wMdA0dafskFfFX2tXZhyPTP68s8qftLCb9G7tpOVSkqpurReJiV8fzkISZUTsaSlAATatnVDcidQPdGqoXdunnFCbIP-LUzMJwTQTrrJazLZv_EeTmJPmw8KgNmkpPrrF-Qp1MV6FRxCUWT5ibqX_1c-ydizTxnzCKgSgUwF73sZbbqURxbjA0yUitzeg39a1Df0Q87eaC2kRwFu81XYaV7fYBBgoycix_qcID2YbN8YC0aXE282MxcisS_LqGVI5t3rrh395XVpI7MgI37u2M_LSFQKHmqnvyKwODf2qlXFPJTjNCzQwvoyA0P5Td8HAm3HU5kv677raBCHzrB4yo1G-CWk5GN5JYArHllWoRsIJ_sXrkv9IhBJ5f9rrE_WAusEQuSBY2zenHC4xpunUwjUgi8QbPIEFfr1uPin2SAKOvw_6g91uOCoAPw4wDpPe28ZIEaaadRB8PlwOZ1N0_2xMpStT_P2nmFKq937aA7r7scFTGoXCPSRaYLjQ29wDO0Z1PT_2PXSGuAeYMMNkFbrZdzxgWwpSXU9PwnE7YClr3nxbOcH9OS6XVQwQYlE0dCFN5T4i4fsSnhUBIfikkjP0Kpy4Uhx48eFT9ak-J03qf0roaqvrpvWtkA5tPDvP4M10pCYo8_P947lkgM_hyabL4H_af43mXaIUIQAUw2-C7vV_fUAah1bUeopAc9LSGNv8jfIUFruRx12LhubBe-1-Y5Nl8gMkkrwyZsWbL6gyW54GroGsOR_J2RWtPcmirsBNwnWIEBhle67_YqiENbGNwy0Q4PXlZkDKiXqDokSFL1iUjKmSjilYPoz81wxV-6iV_sVP4ZpIkl0QFuWCLwg7Lhp79-p6hLOrwHPO8NML4ZuVjghVtsXXOIF9BGCHYUI0Uc_IMgGNkELPat2s2pwEjGpk3ZgRRu3gWVtAtbVDZi5qr68dp4oiSzcRAIrgorr_hTY5TIeFXRy8oxSKTaDY20-dyhKia4aGhGKtGFNz_bCJOdhvZGPtUnfck69dMn6LaI9JRzkKYDPJT512cC-mDs8-OQoYmrL9P8UJlpxdspD0CCwV2bsQgqzMYwEgRn5a3Y9tlkVOU0RHEluQI-eJgs9YSgrmh8nhRYNVIJGm0e9jj9Jbs2s6sDI_M./download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 185.235.236.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|185.235.236.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  22.3MB/s    in 2m 57s  \n",
            "\n",
            "2019-03-21 10:05:09 (22.1 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "36mBTFvPCxY9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rjyr96hR_4wS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Modules\n",
        "\n",
        "We now import the modules we will use in this baseline code. "
      ]
    },
    {
      "metadata": {
        "id": "o0KYfe-at9KN",
        "colab_type": "code",
        "outputId": "920a3592-cb1e-41cd-9fa7-82e7c642cb76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import optimizers\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AFG0LyAct_-l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The `read_data` and `utils` imports are functions provided in the repository we just cloned. You can navigate through the *File tab* and check what those functions do for a better understanding.\n",
        "\n",
        "![texto del enlace](https://i.ibb.co/HnfSvfT/filetab.png)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "2Y61ZKWZ7o5k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We also fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "NXL31ez-AT5h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_OqFkNujBGzf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load the data. The original HPatches dataset has several splits, which are used to separate the available sequences in train sequences and test sequences. For our experiments in N-HPatches we use the same splits as in HPatches. Specifically, we load (and report results) using the split `'a'`:\n"
      ]
    },
    {
      "metadata": {
        "id": "ABKDHB9RApZk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "#we train on the a split of HPatches are specified in the repository\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0rT2fodtyLCo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Establishing size of sequences\n",
        "len(seqs_train)\n",
        "len(seqs_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qeWik0vMEtuC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models and loss"
      ]
    },
    {
      "metadata": {
        "id": "vBRIxhetYrFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This is the implementation of DeepUNet with modifications to some hyperparameters\n",
        "# he uniform was better performing than glorot_uniform \n",
        "\n",
        "def get_denoise_model(shape):\n",
        "  \n",
        "    inputs = Input(shape)\n",
        "    \n",
        "    conv1 = Conv2D(16, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block1_conv1')(inputs)\n",
        "    \n",
        "    conv1 = Conv2D(16, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block1_conv2')(conv1)\n",
        "    \n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    \n",
        "    conv2 = Conv2D(32, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block2_conv1')(pool1)\n",
        "    \n",
        "    conv2 = Conv2D(32, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block2_conv2')(conv2)\n",
        "    \n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    \n",
        "    conv3 = Conv2D(64, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block3_conv1')(pool2)\n",
        "    \n",
        "    conv3 = Conv2D(64, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block3_conv2')(conv3)\n",
        "    \n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(128, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block4_conv1')(pool3)\n",
        "    \n",
        "    conv4 = Conv2D(128, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block4_conv2')(conv4)\n",
        "    \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(256, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block5_conv1')(pool4)\n",
        "    \n",
        "    conv5 = Conv2D(128, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block5_conv2')(conv5)\n",
        "    \n",
        "    up1 = UpSampling2D(size = (2,2))(conv5)\n",
        "    \n",
        "    merge1 = concatenate([conv4,up1])\n",
        "    \n",
        "    conv6 = Conv2D(128, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block6_conv1')(merge1)\n",
        "    \n",
        "    conv6 = Conv2D(64, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block6_conv2')(conv6)\n",
        "    \n",
        "    up2 = UpSampling2D(size = (2,2))(conv6)\n",
        "    \n",
        "    merge2 = concatenate([conv3,up2])\n",
        "\n",
        "    conv7 = Conv2D(64, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block7_conv1')(merge2)\n",
        "    \n",
        "    conv7 = Conv2D(32, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block7_conv2')(conv7)\n",
        "    \n",
        "    up3 = UpSampling2D(size = (2,2))(conv7)\n",
        "    \n",
        "    merge3 = concatenate([conv2,up3])\n",
        "\n",
        "    conv8 = Conv2D(32, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block8_conv1')(merge3)\n",
        "    \n",
        "    conv8 = Conv2D(16, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block8_conv2')(conv8)\n",
        "    \n",
        "    up4 = UpSampling2D(size = (2,2))(conv8)\n",
        "    \n",
        "    merge4 = concatenate([conv1,up4])\n",
        "\n",
        "    conv9 = Conv2D(16, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block9_conv1')(merge4)\n",
        "    \n",
        "    conv9 = Conv2D(32, (3, 3), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block9_conv2')(conv9)\n",
        "\n",
        "    model_output = Conv2D(1, (1, 1), \n",
        "               use_bias=False, padding=\"same\",activation=\"relu\",\n",
        "               strides=1,kernel_initializer='he_uniform',\n",
        "               name='block9_conv3')(conv9)\n",
        "\n",
        "    deep_unet = Model(inputs = inputs, outputs = model_output)\n",
        "  \n",
        "    return deep_unet\n",
        "\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wl_qhlkbYumv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "shape = (32, 32, 1)\n",
        "denoise_model = get_denoise_model(shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xYDdX0Qsxsf",
        "colab_type": "code",
        "outputId": "bff6ceb0-c8fc-4d09-b408-882a2b7162dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1292
        }
      },
      "cell_type": "code",
      "source": [
        "denoise_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 32, 32, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 32, 32, 16)   144         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 32, 32, 16)   2304        block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 16, 16, 16)   0           block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 16, 16, 32)   4608        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 16, 16, 32)   9216        block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 8, 8, 32)     0           block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 8, 8, 64)     18432       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 8, 8, 64)     36864       block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 4, 4, 64)     0           block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 4, 4, 128)    73728       max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 4, 4, 128)    147456      block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 2, 2, 128)    0           block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 2, 2, 256)    294912      max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 2, 2, 128)    294912      block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_17 (UpSampling2D) (None, 4, 4, 128)    0           block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 4, 4, 256)    0           block4_conv2[0][0]               \n",
            "                                                                 up_sampling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block6_conv1 (Conv2D)           (None, 4, 4, 128)    294912      concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block6_conv2 (Conv2D)           (None, 4, 4, 64)     73728       block6_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_18 (UpSampling2D) (None, 8, 8, 64)     0           block6_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 8, 8, 128)    0           block3_conv2[0][0]               \n",
            "                                                                 up_sampling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block7_conv1 (Conv2D)           (None, 8, 8, 64)     73728       concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block7_conv2 (Conv2D)           (None, 8, 8, 32)     18432       block7_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_19 (UpSampling2D) (None, 16, 16, 32)   0           block7_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 64)   0           block2_conv2[0][0]               \n",
            "                                                                 up_sampling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv1 (Conv2D)           (None, 16, 16, 32)   18432       concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_conv2 (Conv2D)           (None, 16, 16, 16)   4608        block8_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_20 (UpSampling2D) (None, 32, 32, 16)   0           block8_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 32, 32, 32)   0           block1_conv2[0][0]               \n",
            "                                                                 up_sampling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv1 (Conv2D)           (None, 32, 32, 16)   4608        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv2 (Conv2D)           (None, 32, 32, 32)   4608        block9_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block9_conv3 (Conv2D)           (None, 32, 32, 1)    32          block9_conv2[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,375,664\n",
            "Trainable params: 1,375,664\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6QbkHnbuIUD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_descriptor_model(shape):\n",
        "  \n",
        "  '''Architecture copies HardNet architecture'''\n",
        "  \n",
        "  init_weights = keras.initializers.he_normal()\n",
        "  \n",
        "  descriptor_model = Sequential()\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', input_shape=shape, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(32, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', strides=2, use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(64, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', strides=2,  use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 3, padding='same', use_bias = True, kernel_initializer=init_weights))\n",
        "  descriptor_model.add(BatchNormalization(axis = -1))\n",
        "  descriptor_model.add(Activation('relu'))\n",
        "  descriptor_model.add(Dropout(0.3))\n",
        "\n",
        "  descriptor_model.add(Conv2D(128, 8, padding='valid', use_bias = True, kernel_initializer=init_weights))\n",
        "  \n",
        "  # Final descriptor reshape\n",
        "  descriptor_model.add(Reshape((128,)))\n",
        "  \n",
        "  return descriptor_model\n",
        "  \n",
        "  \n",
        "def triplet_loss(x):\n",
        "  \n",
        "  output_dim = 128\n",
        "  a, p, n = x\n",
        "  _alpha = 1.0\n",
        "  positive_distance = K.mean(K.square(a - p), axis=-1)\n",
        "  negative_distance = K.mean(K.square(a - n), axis=-1)\n",
        "  \n",
        "  return K.expand_dims(K.maximum(0.0, positive_distance - negative_distance + _alpha), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RlS5zcV7EJgp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Denoising Image Patches\n"
      ]
    },
    {
      "metadata": {
        "id": "wHxHwjUd3-pY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We use the *DenoiseHPatches* class implemented in the read_data.py file, which takes as input the list of sequences to load and the size of batches. \n",
        "\n",
        "*DenoiseHPatches* outputs batches where the input data is the noisy image and the label is the clean image, so we can use a mean absolute error (MAE) metric as loss function. You can try to use different metrics here to see if that improves results. \n",
        "\n",
        "Afterward, we take a subset of training and validation sequences by using *random.sample* (3 sequences for training and 1 for validation data). The purpose of doing so is just to speed-up training when trying different setups, but you should use the whole dataset when training your final model. Remove the random.sample function to give the generator all the training data.\n",
        "\n",
        "In addition, note that we are using the test set as validation. We will provide you with a new test set that will be used to evaluate your final model, and from which you will not have the clean images. \n",
        "\n",
        "**Updated**: Training should be quite faster now (1 epoch around 15 minutes)."
      ]
    },
    {
      "metadata": {
        "id": "m_VPSHmSK0dS",
        "colab_type": "code",
        "outputId": "4cd0ee20-f4d2-4692-9ce1-796714cb0932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# This is the sample sizing for monitoring and adjusting an unoptimised model\n",
        "#denoise_generator = DenoiseHPatches(random.sample(seqs_train, 8), batch_size=32)\n",
        "#denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 2), batch_size=32)\n",
        "\n",
        "# This is the 'whole' training set for upgraded model due to colab GPU constraints\n",
        "denoise_generator = DenoiseHPatches(random.sample(seqs_train, 28), batch_size=32)\n",
        "denoise_generator_val = DenoiseHPatches(random.sample(seqs_test, 7), batch_size=32)\n",
        "\n",
        "# Uncomment following lines for using all the data to train the denoising model\n",
        "# Only used for baseline model\n",
        "#denoise_generator = DenoiseHPatches(seqs_train, batch_size=32)\n",
        "#denoise_generator_val = DenoiseHPatches(seqs_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 28/28 [00:25<00:00,  1.06it/s]\n",
            "100%|██████████| 7/7 [00:08<00:00,  1.03s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "H3wkjkpk4bRh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We set number of epochs to 1, tweak it, along with other hyperparameters, to improve the performance of the model."
      ]
    },
    {
      "metadata": {
        "id": "edwbgE6yKqcD",
        "colab_type": "code",
        "outputId": "bf3d739c-2cc4-4e5f-ef22-b303785c054c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "cell_type": "code",
      "source": [
        "#sgd = keras.optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n",
        "\n",
        "# New optimiser and learning rate decreased by a factor of 10\n",
        "Adam = keras.optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "denoise_model.compile(loss='mean_absolute_error', optimizer=Adam, metrics=['mae', 'acc'])\n",
        "\n",
        "# Reload the model to train since it keeps disconnecting rip\n",
        "# denoise_model.set_weights(keras.models.load_model('./upgraded_denoise.h5').get_weights())\n",
        "# denoise_model.optimizer = keras.models.load_model('./upgraded_denoise.h5').optimizer\n",
        "\n",
        "#denoise_model = keras.models.load_model('./upgraded_denoise.h5')\n",
        "\n",
        "#Patience set to 8 due to length of time required for whole dataset epoch runs. Usually value would be 10-20.  \n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=8)\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "### Use a loop to save for each epoch the weights in an external website in\n",
        "### case colab stops. Every time you call fit/fit_generator the weigths are NOT\n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "for e in range(epochs):\n",
        "  denoise_history = denoise_model.fit_generator(generator=denoise_generator, \n",
        "                                                epochs=1, verbose=1, \n",
        "                                                validation_data=denoise_generator_val)\n",
        "  ### Saves optimizer and weights\n",
        "  denoise_model.save('upgraded_denoise.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  #!curl -F \"file=@denoise.h5\" https://file.io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 595s 35ms/step - loss: 9.5480 - mean_absolute_error: 9.5480 - acc: 0.0479 - val_loss: 6.6565 - val_mean_absolute_error: 6.6565 - val_acc: 0.0591\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 594s 35ms/step - loss: 6.7664 - mean_absolute_error: 6.7664 - acc: 0.0611 - val_loss: 6.0761 - val_mean_absolute_error: 6.0761 - val_acc: 0.0659\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 582s 35ms/step - loss: 6.2687 - mean_absolute_error: 6.2687 - acc: 0.0683 - val_loss: 5.6966 - val_mean_absolute_error: 5.6966 - val_acc: 0.0749\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 566s 34ms/step - loss: 6.0309 - mean_absolute_error: 6.0309 - acc: 0.0735 - val_loss: 5.5564 - val_mean_absolute_error: 5.5564 - val_acc: 0.0777\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 570s 34ms/step - loss: 5.8948 - mean_absolute_error: 5.8948 - acc: 0.0764 - val_loss: 5.4393 - val_mean_absolute_error: 5.4393 - val_acc: 0.0812\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 570s 34ms/step - loss: 5.7866 - mean_absolute_error: 5.7866 - acc: 0.0802 - val_loss: 5.3693 - val_mean_absolute_error: 5.3693 - val_acc: 0.0839\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 563s 33ms/step - loss: 5.6993 - mean_absolute_error: 5.6993 - acc: 0.0846 - val_loss: 5.2738 - val_mean_absolute_error: 5.2738 - val_acc: 0.0906\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 562s 33ms/step - loss: 5.6311 - mean_absolute_error: 5.6311 - acc: 0.0878 - val_loss: 5.2255 - val_mean_absolute_error: 5.2255 - val_acc: 0.0944\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 574s 34ms/step - loss: 5.5750 - mean_absolute_error: 5.5750 - acc: 0.0905 - val_loss: 5.1722 - val_mean_absolute_error: 5.1722 - val_acc: 0.0945\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 551s 33ms/step - loss: 5.5269 - mean_absolute_error: 5.5269 - acc: 0.0928 - val_loss: 5.1428 - val_mean_absolute_error: 5.1428 - val_acc: 0.0996\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.4859 - mean_absolute_error: 5.4859 - acc: 0.0946 - val_loss: 5.1119 - val_mean_absolute_error: 5.1119 - val_acc: 0.0958\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 552s 33ms/step - loss: 5.4492 - mean_absolute_error: 5.4492 - acc: 0.0965 - val_loss: 5.0899 - val_mean_absolute_error: 5.0899 - val_acc: 0.0982\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 550s 33ms/step - loss: 5.4160 - mean_absolute_error: 5.4160 - acc: 0.0981 - val_loss: 5.0659 - val_mean_absolute_error: 5.0659 - val_acc: 0.1049\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 555s 33ms/step - loss: 5.3871 - mean_absolute_error: 5.3871 - acc: 0.0995 - val_loss: 5.0326 - val_mean_absolute_error: 5.0326 - val_acc: 0.1066\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.3602 - mean_absolute_error: 5.3602 - acc: 0.1010 - val_loss: 5.0130 - val_mean_absolute_error: 5.0130 - val_acc: 0.1081\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.3358 - mean_absolute_error: 5.3358 - acc: 0.1021 - val_loss: 5.0207 - val_mean_absolute_error: 5.0207 - val_acc: 0.1096\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.3136 - mean_absolute_error: 5.3136 - acc: 0.1033 - val_loss: 5.0034 - val_mean_absolute_error: 5.0034 - val_acc: 0.1073\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 552s 33ms/step - loss: 5.2928 - mean_absolute_error: 5.2928 - acc: 0.1044 - val_loss: 5.0243 - val_mean_absolute_error: 5.0243 - val_acc: 0.0934\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 551s 33ms/step - loss: 5.2739 - mean_absolute_error: 5.2739 - acc: 0.1056 - val_loss: 4.9575 - val_mean_absolute_error: 4.9575 - val_acc: 0.1116\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 558s 33ms/step - loss: 5.2562 - mean_absolute_error: 5.2562 - acc: 0.1067 - val_loss: 4.9466 - val_mean_absolute_error: 4.9466 - val_acc: 0.1135\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 560s 33ms/step - loss: 5.2392 - mean_absolute_error: 5.2392 - acc: 0.1076 - val_loss: 4.9459 - val_mean_absolute_error: 4.9459 - val_acc: 0.1147\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 557s 33ms/step - loss: 5.2229 - mean_absolute_error: 5.2229 - acc: 0.1088 - val_loss: 4.9284 - val_mean_absolute_error: 4.9284 - val_acc: 0.1092\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 557s 33ms/step - loss: 5.2089 - mean_absolute_error: 5.2089 - acc: 0.1094 - val_loss: 4.9198 - val_mean_absolute_error: 4.9198 - val_acc: 0.1133\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 584s 35ms/step - loss: 5.1947 - mean_absolute_error: 5.1947 - acc: 0.1104 - val_loss: 4.9064 - val_mean_absolute_error: 4.9064 - val_acc: 0.1148\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 567s 34ms/step - loss: 5.1815 - mean_absolute_error: 5.1815 - acc: 0.1111 - val_loss: 4.8935 - val_mean_absolute_error: 4.8935 - val_acc: 0.1164\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 559s 33ms/step - loss: 5.1688 - mean_absolute_error: 5.1688 - acc: 0.1120 - val_loss: 4.8926 - val_mean_absolute_error: 4.8926 - val_acc: 0.1175\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 556s 33ms/step - loss: 5.1565 - mean_absolute_error: 5.1565 - acc: 0.1128 - val_loss: 4.9181 - val_mean_absolute_error: 4.9181 - val_acc: 0.1078\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.1458 - mean_absolute_error: 5.1458 - acc: 0.1133 - val_loss: 4.8855 - val_mean_absolute_error: 4.8855 - val_acc: 0.1176\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 554s 33ms/step - loss: 5.1342 - mean_absolute_error: 5.1342 - acc: 0.1140 - val_loss: 4.8685 - val_mean_absolute_error: 4.8685 - val_acc: 0.1217\n",
            "Epoch 1/1\n",
            "16831/16831 [==============================] - 553s 33ms/step - loss: 5.1235 - mean_absolute_error: 5.1235 - acc: 0.1146 - val_loss: 4.8577 - val_mean_absolute_error: 4.8577 - val_acc: 0.1225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yHqx38ELi_66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hardly used due to the fact that we saved each epoch individually in case GPU disconnected\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(history, metric = None):\n",
        "  # Plots the loss history of training and validation (if existing)\n",
        "  # and a given metric\n",
        "  \n",
        "  if metric != None:\n",
        "    fig, axes = plt.subplots(2,1)\n",
        "    axes[0].plot(history.history[metric])\n",
        "    try:\n",
        "      axes[0].plot(history.history['val_'+metric])\n",
        "      axes[0].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[0].set_title('{:s}'.format(metric))\n",
        "    axes[0].set_ylabel('{:s}'.format(metric))\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    fig.subplots_adjust(hspace=0.5)\n",
        "    axes[1].plot(history.history['loss'])\n",
        "    try:\n",
        "      axes[1].plot(history.history['val_loss'])\n",
        "      axes[1].legend(['Train', 'Val'])\n",
        "    except:\n",
        "      pass\n",
        "    axes[1].set_title('Model Loss')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "\n",
        "    \n",
        "#Only runs when epochs are specified in the loop but chose to specify outside incase of collab quitting so that weights were saved in h5 files. \n",
        "plot_history(denoise_history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gQHYYfqz8Cf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make sure file is in keras_descriptor folder!\n",
        "#For loading previous weights\n",
        "#denoise_model = keras.models.load_model('./denoise.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e9FzSZzMEcs4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization of Denoising Results\n",
        "To visualize how the denoised patches look, you can run the following function. It returns the noisy patch, the denoised patch in the middle, and the clean patch in the right side. "
      ]
    },
    {
      "metadata": {
        "id": "XFA_8uN4Eb3B",
        "colab_type": "code",
        "outputId": "b4909f14-035c-4b5f-f962-70859aa9878d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "cell_type": "code",
      "source": [
        "plot_denoise(denoise_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "SyABaCvkEPDR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training a Descriptor Network\n",
        "In the last section we trained a model that given a noisy patch, outputs a denoised version of it. We hoped that by doing so, we will improve the performance of the second part, which is training a network that outputs the descriptor. As we mentioned, a descriptor is a numerical vector that represents the small images we have. The dataset consists of a large number of small images, which are cropped patches from other larger images. Hence, they represent some local part of a scene. That is why there are no objects represented, only corners or textures. Each of these patches is related to a subset of other patches of the dataset by some kind of geometric transformation (e.g. rotation).  For a given patch, we want the network to output a vector that is close to the vectors of the patches that represent the same local part of a scene, while being far from patches do not represent that local part of a scene.\n",
        "\n",
        "To do so, we will build a convolutional neural network that takes the input of $32\\times32$ and outputs a descriptor of size $128$. For the loss, we use the triplet loss, which takes an anchor patch, a negative patch and a positive patch. The idea is to train the network so the descriptors from the anchor and positive patch have a low distance between them, and the negative and anchor patch have a large distance between them. \n",
        "\n",
        "In this cell we generate a triplet network, which is a network formed by three copies of the same network. That means that the descriptor model will compute the descriptor for the input `'a'` (anchor), the same descriptor model (with the same weights) will compute the descriptor for the input `'p'` (positive), and again the same model will compute the descriptor for the input `'n'` (negative). \n",
        "\n",
        "**Updated explanation**: Due to the way Keras handles the compile method, it needs a loss as an argument in that compile method. However, our loss is computed in the lambda layer, so we want to minimize the output of that layer. As we want to minimize the output of the Lambda function (in this case the triplet loss), we output as the label in the training_generator a vector of zeros and we compute the mean absolute error of the triplet loss and this vector of zeros. To give you an intuition, what we aim to minimize is\n",
        "$$  |\\text{triplet_loss} - 0| =  |\\text{triplet_loss}| = \\text{triplet_loss} $$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DVmDZIRTHPDa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Lambda\n",
        "shape = (32, 32, 1)\n",
        "xa = Input(shape=shape, name='a')\n",
        "xp = Input(shape=shape, name='p')\n",
        "xn = Input(shape=shape, name='n')\n",
        "descriptor_model = get_descriptor_model(shape)\n",
        "ea = descriptor_model(xa)\n",
        "ep = descriptor_model(xp)\n",
        "en = descriptor_model(xn)\n",
        "\n",
        "loss = Lambda(triplet_loss)([ea, ep, en])\n",
        "\n",
        "descriptor_model_trip = Model(inputs=[xa, xp, xn], outputs=loss)\n",
        "\n",
        "#lr decreased by 10, added Nesterov default momentum \n",
        "#sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "Adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "descriptor_model_trip.compile(loss='mean_absolute_error', optimizer=sgd, metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7u8w25ANiN1F",
        "colab_type": "code",
        "outputId": "d0b8565c-9b59-496c-bf9f-4aed8f672d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "cell_type": "code",
      "source": [
        "descriptor_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 32, 32, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 1, 1, 128)         1048704   \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 128)               0         \n",
            "=================================================================\n",
            "Total params: 1,336,928\n",
            "Trainable params: 1,336,032\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BllXKocHCwZ7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use the class HPatches, which loads the corresponding files by using the method `read_image_file`. It reads the patches. The output of read_image_file is a tuple of the form (images, labels), which is passed to the class `DataGeneratorDesc`. This class is a generator that creates batches of triplets, and each epoch is defined by the number of triplets in the argument `num_triplets`.\n",
        "\n",
        "**Updated**: In the previous version of the baseline code, we were training the descriptor model with the noisy patches, not with the denoised ones. By adding the argument `denoise_model=denoise_model` to the class HPatches we can use the denoised images instead to train this descriptor model (if `denoise_model=None`, the noisy patches will be used). However, as it has to compute the denoised patch first, the loading of the data will be slower (6/7 extra min).  If you want to train the model with the clean patches instead, you can set the argument `use_clean=True`. In this last case, even if a denoise model is given, it will not be used. When running this piece of code **the type of patches (denoised, noisy or clean) used is printed**."
      ]
    },
    {
      "metadata": {
        "id": "4Zn7oEur8OU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "denoise_model = get_denoise_model('./denoise.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YIR1cH4fDwKj",
        "colab_type": "code",
        "outputId": "40d556be-7059-4e38-e3dc-dc23ba78d403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "### Descriptor loading and training\n",
        "# Loading images\n",
        "hPatches = HPatches(train_fnames=train_fnames, test_fnames=test_fnames,\n",
        "                    denoise_model=denoise_model, use_clean=False)\n",
        "# Creating training generator\n",
        "training_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=1), num_triplets=120000)\n",
        "# Creating validation generator\n",
        "val_generator = DataGeneratorDesc(*hPatches.read_image_file(hpatches_dir, train=0), num_triplets=30000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using denoised patches\n",
            "100%|██████████| 116/116 [00:36<00:00,  3.13it/s]\n",
            "Denoising patches...\n",
            "100%|██████████| 15589/15589 [06:43<00:00, 38.65it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:02<00:00, 54388.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using denoised patches\n",
            "100%|██████████| 116/116 [00:21<00:00,  5.29it/s]\n",
            "Denoising patches...\n",
            "100%|██████████| 9525/9525 [04:04<00:00, 38.90it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 30000/30000 [00:00<00:00, 81496.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "GoQYyuD7_4PS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We plot a random triplet in the form of anchor, positive and negative sample. The positive and anchor patches are similar between them (the difference is a geometric transformation, for example rotation), whereas the negative sample should be quite dissimilar to any of the other two."
      ]
    },
    {
      "metadata": {
        "id": "3RQmOMU92csu",
        "colab_type": "code",
        "outputId": "9fc6f653-1b77-4240-c3e7-338e096a8b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "cell_type": "code",
      "source": [
        "plot_triplet(training_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAACmCAYAAABXw78OAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCA80YQohhBAe/B/HnwmTrAFg+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "UaE2_6HUCAOw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now train the descriptor model and save the weights afterward."
      ]
    },
    {
      "metadata": {
        "id": "QPyc8as42WTQ",
        "colab_type": "code",
        "outputId": "d2e8e4f0-8fe6-48df-e5c7-bcde4f4a9f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1275
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "### As with the denoising model, we use a loop to save for each epoch \n",
        "## #the weights in an external website in case colab stops. \n",
        "### reset, so e.g. calling 5 times fit(epochs=1) behave as fit(epochs=5)\n",
        "\n",
        "### If you have a model saved from a previous training session\n",
        "### Load it in the next line\n",
        "# descriptor_model_trip.set_weights(keras.models.load_model('./descriptor.h5').get_weights())\n",
        "# descriptor_model_trip.optimizer = keras.models.load_model('./descriptor.h5').optimizer\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  descriptor_history = descriptor_model_trip.fit_generator(generator=training_generator, epochs=1, verbose=1, validation_data=val_generator)\n",
        "  \n",
        "  ### Saves optimizer and weights\n",
        "  descriptor_model_trip.save('descriptor.h5') \n",
        "  ### Uploads files to external hosting\n",
        "  #!curl -F \"file=@descriptor.h5\" https://file.io\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.8799"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:05<00:00, 22440.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 210s 87ms/step - loss: 0.1982 - acc: 0.8799 - val_loss: 0.1948 - val_acc: 0.8910\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9100"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 27537.33it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.1486 - acc: 0.9100 - val_loss: 0.1902 - val_acc: 0.8783\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:05<00:00, 22296.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 205s 85ms/step - loss: 0.1319 - acc: 0.9197 - val_loss: 0.1585 - val_acc: 0.9027\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9255"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26317.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.1215 - acc: 0.9255 - val_loss: 0.1747 - val_acc: 0.8904\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9265"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26639.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.1182 - acc: 0.9264 - val_loss: 0.1543 - val_acc: 0.9057\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9315"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 27554.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.1108 - acc: 0.9315 - val_loss: 0.1630 - val_acc: 0.8975\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9329"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26970.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 204s 85ms/step - loss: 0.1076 - acc: 0.9329 - val_loss: 0.1356 - val_acc: 0.9177\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 27215.73it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.1053 - acc: 0.9344 - val_loss: 0.1399 - val_acc: 0.9132\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9373"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26624.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 86ms/step - loss: 0.1008 - acc: 0.9373 - val_loss: 0.1297 - val_acc: 0.9204\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9366"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 27315.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 86ms/step - loss: 0.1005 - acc: 0.9366 - val_loss: 0.1262 - val_acc: 0.9196\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9383"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26044.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.0974 - acc: 0.9383 - val_loss: 0.1350 - val_acc: 0.9181\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9394"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26126.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.0961 - acc: 0.9394 - val_loss: 0.1313 - val_acc: 0.9180\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9417"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26609.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.0939 - acc: 0.9417 - val_loss: 0.1454 - val_acc: 0.9134\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9408"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26937.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.0933 - acc: 0.9407 - val_loss: 0.1234 - val_acc: 0.9252\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9424"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26953.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.0912 - acc: 0.9424 - val_loss: 0.1364 - val_acc: 0.9157\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9428"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26685.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 205s 85ms/step - loss: 0.0906 - acc: 0.9427 - val_loss: 0.1700 - val_acc: 0.8914\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9446"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 25858.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 204s 85ms/step - loss: 0.0882 - acc: 0.9446 - val_loss: 0.1349 - val_acc: 0.9167\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 25818.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2400/2400 [==============================] - 209s 87ms/step - loss: 0.0897 - acc: 0.9433 - val_loss: 0.1474 - val_acc: 0.9116\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9455"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 25825.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 206s 86ms/step - loss: 0.0861 - acc: 0.9455 - val_loss: 0.1169 - val_acc: 0.9286\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:05<00:00, 23088.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 207s 86ms/step - loss: 0.0819 - acc: 0.9476 - val_loss: 0.1410 - val_acc: 0.9172\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9476"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26212.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 206s 86ms/step - loss: 0.0816 - acc: 0.9476 - val_loss: 0.1206 - val_acc: 0.9253\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9469"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:05<00:00, 23089.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 208s 87ms/step - loss: 0.0831 - acc: 0.9469 - val_loss: 0.1354 - val_acc: 0.9194\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9481"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:04<00:00, 26262.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 207s 86ms/step - loss: 0.0803 - acc: 0.9481 - val_loss: 0.1129 - val_acc: 0.9265\n",
            "Epoch 1/1\n",
            "2399/2400 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9505"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 120000/120000 [00:05<00:00, 22530.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2400/2400 [==============================] - 208s 86ms/step - loss: 0.0770 - acc: 0.9505 - val_loss: 0.1123 - val_acc: 0.9286\n",
            "Epoch 1/1\n",
            " 561/2400 [======>.......................] - ETA: 2:26 - loss: 0.0752 - acc: 0.9517Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJ-r9D4hDxij",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generating descriptors files for test data \n",
        "\n",
        "To evaluate the performance of out model we will use an existing evaluation code, which is called HPatches benchmark. HPatches benchmark takes as input the descriptors for the test data in a CSV form. So the whole pipeline is represented in the following image.\n",
        "\n",
        "![](https://i.ibb.co/WcDDf3q/Screenshot-from-2019-02-15-11-17-24.png)\n",
        "\n",
        "This function generates those files by passing it a descriptor model and a denoising model. It performs a first step of denoising the patches, and a second one of computing the descriptor of the denoised patch. If no denoising model is given (variable set to `None`), the descriptor is computed directly in the noisy patch.\n",
        "\n",
        "Similarly to the loading data part, you have the denoise_model variable and `use_clean` variable. If `use_clean` is set to True, the CSV generated will be those of the clean patches, even if a denoising model is given. If set to False, then depends on the variable `denoise_model`. If there is no denoise model (`denoise_model=None`), then it will use the noisy patches. If you give a denoising model, then it will compute the CSV for the denoised patches. This can be useful to explore different scenarios (for example, the Upper Bound can be training the descriptor network with clean patches, and testing with clean patches), however you should always report the score when using noisy patches (depending on the approach you develop, you may want to denoise them or not). The official baseline uses the denoised patches. "
      ]
    },
    {
      "metadata": {
        "id": "kiJb2XDG9bsJ",
        "colab_type": "code",
        "outputId": "0c269cc9-d7c9-4c90-8813-a3fc7d5b40bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "generate_desc_csv(descriptor_model, seqs_test, denoise_model=denoise_model, use_clean=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [08:02<00:00, 11.27s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0jFr05rE1oI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating descriptors in HPatches Benchmark\n",
        "We use HPatches benchmark code to compute the results for our model. \n",
        "\n",
        "**Updated**: The necessary code is included in the repository we cloned at the beginning of the code, so we do not need to download any extra data. Also, we simplified the results, so now they only return one value for each of the three tasks."
      ]
    },
    {
      "metadata": {
        "id": "YvOGRh3sc9Wo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will perform the evaluation of three different tasks (Verification, Matching and Evaluation) using the CSV files we generated as input and the `hpatches_eval.py` script. We also print the results using the `hpatches_results.py` script. The scripts will return a score for each of the tasks. The metric used is called mean Average Precision, which it uses the Precision of the model. The Precision is defined, for a given number of retrieved elements, as the ratio of correct retrieved elements / number of retrieved elements. [Link to Wikipedia with Precision explanation](https://en.wikipedia.org/wiki/Precision_and_recall). The definition of the three different tasks is taken from the [HPatches paper](https://arxiv.org/pdf/1704.05939.pdf).\n",
        "\n",
        "In all of the tasks if you use the optional argument `--more_info` in `hpatches_results.py` you can see extra mAP information. However, the important score is the mAP score reported without this flag.\n",
        "\n",
        "### Verification\n",
        "\n",
        "Patch verification measures the ability of a descriptor to classify whether two patches are extracted from the same measurement. Now we compute the score of our architecture in this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Awnyv4xTYSFH",
        "colab_type": "code",
        "outputId": "c2d5d990-eb9b-4ed1-dcb8-1799cb5ecf92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=verification --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=verification\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mverification\u001b[0m task\n",
            "Processing verification task 1/3 : 100% 1000000/1000000 [01:25<00:00, 11654.78it/s]\n",
            "Processing verification task 2/3 : 100% 1000000/1000000 [01:25<00:00, 11674.54it/s]\n",
            "Processing verification task 3/3 : 100% 1000000/1000000 [01:26<00:00, 11600.46it/s]\n",
            ">> \u001b[32mVerification\u001b[0m task finished in 266 secs  \n",
            "\u001b[32mVerification\u001b[0m task results:\n",
            "Mean Average Precision is 0.806913\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5290Bw-udJdr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Matching\n",
        "Image matching, tests to what extent a descriptor can correctly identify correspondences in two images."
      ]
    },
    {
      "metadata": {
        "id": "EUqpwi87ckJv",
        "colab_type": "code",
        "outputId": "b9e0f432-e375-4b02-f76a-e5e8202a6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=matching --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=matching\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mmatching\u001b[0m task\n",
            "100% 40/40 [02:11<00:00,  4.45s/it]\n",
            ">> \u001b[32mMatching\u001b[0m task finished in 131 secs  \n",
            "\u001b[32mMatching\u001b[0m task results:\n",
            "Mean Average Precision is 0.217416\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RXXgbN7DdMnx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Retrieval\n",
        "Retrieval tests how well a descriptor can match a query patch to a pool of patches extracted from many images."
      ]
    },
    {
      "metadata": {
        "id": "ZNmKIat1cn_M",
        "colab_type": "code",
        "outputId": "6cfa855a-a7c8-4485-be08-3fcf6eccddc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "cell_type": "code",
      "source": [
        "!python ./hpatches-benchmark/hpatches_eval.py --descr-name=custom --descr-dir=/content/keras_triplet_descriptor/out/ --task=retrieval --delimiter=\";\"\n",
        "!python ./hpatches-benchmark/hpatches_results.py --descr=custom --results-dir=./hpatches-benchmark/results/ --task=retrieval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Running HPatch evaluation for \u001b[34mcustom\u001b[0m\n",
            ">> Please wait, loading the descriptor files...\n",
            ">> Descriptor files loaded.\n",
            ">> Evaluating \u001b[32mretrieval\u001b[0m task\n",
            ">> Please wait, computing distance matrix...\n",
            "tcmalloc: large alloc 1600004096 bytes == 0x55c1d8e4c000 @  0x7f4a30c0a1e7 0x7f4a2680bcf1 0x7f4a2686e3a2 0x7f4a268700de 0x7f4a269070e8 0x55c1b0abdfe5 0x55c1b0ab3d0a 0x55c1b0abb5fe 0x55c1b0abb232 0x55c1b0ab3d0a 0x55c1b0abbc38 0x55c1b0ab3d0a 0x55c1b0ab3629 0x55c1b0ae461f 0x55c1b0adf322 0x55c1b0ade67d 0x55c1b0a8d1ab 0x7f4a30807b97 0x55c1b0a8ca2a\n",
            ">> Distance matrix done.\n",
            "Processing retrieval task: 100% 10000/10000 [03:53<00:00, 42.85it/s]\n",
            ">> \u001b[32mRetrieval\u001b[0m task finished in 252 secs  \n",
            "\u001b[32mRetrieval\u001b[0m task results:\n",
            "Mean Average Precision is 0.523319\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}